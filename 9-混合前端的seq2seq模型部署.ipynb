{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 混合前端的seq2seq模型部署\n",
    "\n",
    "# 本教程将介绍如何是seq2seq模型转换为PyTorch可用的前端混合Torch脚本。我们要转换的模型来自于聊天机器人教程Chatbot tutorial。\n",
    "\n",
    "# 1.混合前端\n",
    "# 在一个基于深度学习项目的研发阶段, 使用像PyTorch这样即时eager、命令式的界面进行交互能带来很大便利。 \n",
    "# 这使用户能够在使用Python数据结构、控制流操作、打印语句和调试实用程序时通过熟悉的、惯用的Python脚本编写。\n",
    "\n",
    "# 尽管即时性界面对于研究和试验应用程序是一个有用的工具，但是对于生产环境中部署模型时，使用基于图形graph-based的模型表示将更加适用的。 \n",
    "# 一个延迟的图型展示意味着可以优化，比如无序执行操作，以及针对高度优化的硬件架构的能力。 \n",
    "# 此外，基于图形的表示支持框架无关的模型导出。PyTorch提供了将即时模式的代码增量转换为Torch脚本的机制，\n",
    "# Torch脚本是一个在Python中的静态可分析和可优化的子集，Torch使用它来在Python运行时独立进行深度学习。\n",
    "\n",
    "# 在Torch中的torch.jit模块可以找到将即时模式的PyTorch程序转换为Torch脚本的API。 \n",
    "# 这个模块有两个核心模式用于将即时模式模型转换为Torch脚本图形表示: 跟踪tracing以及脚本化scripting。\n",
    "# torch.jit.trace 函数接受一个模块或者一个函数和一组示例的输入，然后通过函数或模块运行输入示例，\n",
    "# 同时跟跟踪遇到的计算步骤，然后输出一个可以展示跟踪流程的基于图形的函数。\n",
    "# 跟踪Tracing对于不涉及依赖于数据的控制流的直接的模块和函数非常有用，就比如标准的卷积神经网络。\n",
    "\n",
    "# 然而，如果一个有数据依赖的if语句和循环的函数被跟踪，则只记录示例输入沿执行路径调用的操作。\n",
    "# 换句话说，控制流本身并没有被捕获。要将带有数据依赖控制流的模块和函数进行转化，已提供了一个脚本化机制。\n",
    "# 脚本显式地将模块或函数代码转换为Torch脚本，包括所有可能的控制流路径。 如需使用脚本模式script mode， \n",
    "# 要确定继承了 torch.jit.ScriptModule基本类 (取代torch.nn.Module) 并且增加 torch.jit.script 装饰器到你的Python函数或者 \n",
    "# torch.jit.script_method 装饰器到你的模块方法。\n",
    "\n",
    "# 使用脚本化的一个警告是，它只支持Python的一个受限子集。要获取与支持的特性相关的所有详细信息，\n",
    "# 请参考 Torch Script language reference。为了达到最大的灵活性，可以组合Torch脚本的模式来表示整个程序，\n",
    "# 并且可以增量地应用这些技术。 \n",
    "# 混合前端的流程图：图片缺\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch.jit.ScriptModule'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-0f1cd4eedd8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScriptModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch.jit.ScriptModule'"
     ]
    }
   ],
   "source": [
    "# 2 预备环境\n",
    "\n",
    "# 首先，导入所需的模块以及设置一些常量。如果想使用自己的模型，需要保证MAX_LENGTH常量设置正确。 \n",
    "# 提醒：这个常量定义了在训练过程中允许的最大句子长度以及模型能够产生的最大句子长度输出。\n",
    "# source-python\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.jit.ScriptModule\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "MAX_LENGTH = 10 # Maximum sentence length\n",
    "\n",
    "# 默认的词向量\n",
    "PAD_token = 0 # Used for padding short sentences\n",
    "SOS_token = 1 # Start-of-sentence token\n",
    "EOS_token = 2 # End-of-sentence token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.模型概述\n",
    "\n",
    "# 正如前文所言，我们使用的sequence-to-sequence (seq2seq) 模型。\n",
    "# 这种类型的模型用于输入是可变长度序列的情况，我们的输出也是一个可变长度序列，它不一定是一对一输入映射。\n",
    "# seq2seq 模型由两个递归神经网络(RNNs)组成：编码器 encoder和解码器decoder. \n",
    "# 模型概述图片：图片缺\n",
    "\n",
    "# （1）编码器(Encoder)\n",
    "# 编码器RNN在输入语句中每次迭代一个标记(例如单词)，每次步骤输出一个“输出”向量和一个“隐藏状态”向量。\n",
    "# ”隐藏状态“向量在之后则传递到下一个步骤，同时记录输出向量。\n",
    "# 编码器将序列中每个坐标代表的文本转换为高维空间中的一组坐标，解码器将使用这些坐标为给定的任务生成有意义的输出。\n",
    "\n",
    "# （2）解码器(Decoder)\n",
    "# 解码器RNN以逐个令牌的方式生成响应语句。它使用来自于编码器的文本向量和内部隐藏状态来生成序列中的下一个单词。\n",
    "# 它继续生成单词，直到输出表示句子结束的EOS语句。我们在解码器中使用专注机制attention mechanism来帮助它\n",
    "# 在输入的某些部分生成输出时\"保持专注\"。对于我们的模型，我们实现了Luong et al等人的“全局关注Global attention”模块，\n",
    "# 并将其作为解码模型中的子模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4.数据处理\n",
    "\n",
    "# 尽管我们的模型在概念上处理标记序列，但在现实中，它们与所有机器学习模型一样处理数字。\n",
    "# 在这种情况下，在训练之前建立的模型词汇表中的每个单词都映射到一个整数索引。\n",
    "# 我们使用Voc对象来包含从单词到索引的映射，以及词汇表中的单词总数。我们将在运行模型之前加载对象。\n",
    "\n",
    "# 此外，为了能够进行评估，我们必须提供一个处理字符串输入的工具。normalizeString函数将字符串中的所有字符转换为小写，\n",
    "# 并删除所有非字母字符。indexesFromSentence函数接受一个单词的句子并返回相应的单词索引序列。\n",
    "\n",
    "class Voc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3 # 统计SOS, EOS, PAD\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words # 对每个word依次分配index\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # Remove words below a certain count threshold\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed = True\n",
    "        keep_words = []\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k) #这样处理后，词频信息丢掉了\n",
    "\n",
    "        print('keep_words {} / {} = {:.4f}'.format(\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3 # 统计默认的令牌\n",
    "        for word in keep_words:\n",
    "            self.addWord(word) # trimmed后，word对应的index可能发生变化，但其实无所谓....\n",
    "\n",
    "# 小写并删除非字母字符\n",
    "def normalizeString(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "# 使用字符串句子，返回单词索引的句子\n",
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5.定义编码器\n",
    "\n",
    "# 这里大概说一下pytorch的RNN的一些用法，参考： https://www.jianshu.com/p/b942e65cb0a3\n",
    "# Torch中的CNN和RNN中的batchSize的默认位置是不同的。\n",
    "# CNN中：batchsize的位置是position 0.\n",
    "# RNN中：batchsize的位置是position 1.\n",
    "\n",
    "# 在RNN中输入数据格式：\n",
    "# 对于最简单的RNN，我们可以使用两种方式来调用,torch.nn.RNNCell(),它只接受序列中的单步输入，必须显式的传入隐藏状态。\n",
    "# torch.nn.RNN()可以接受一个序列的输入，默认会传入一个全0的隐藏状态，也可以自己申明隐藏状态传入。\n",
    "\n",
    "# 输入大小是三维tensor[seq_len,batch_size,input_dim]\n",
    "# input_dim是输入的维度，比如是128   通常tokenizer之后embeding的维度\n",
    "# batch_size是一次往RNN输入句子的数目，比如是5。\n",
    "# seq_len是一个句子的最大长度，比如15   通常是定义一个最大的长度，不足的部分补一个特殊的token，比如TOKEN_PAD\n",
    "# 所以千万注意，RNN输入的是序列，一次把批次的所有句子都输入了，得到的ouptut和hidden都是这个批次的所有的输出和隐藏状态，维度也是三维。\n",
    "# **可以理解为现在一共有batch_size个独立的RNN组件，RNN的输入维度是input_dim，\n",
    "# 总共输入seq_len个时间步，则每个时间步输入到这个整个RNN模块的维度是[batch_size,input_dim]\n",
    "# 例如：\n",
    "# 构造RNN网络，x的维度5，隐层的维度10,网络的层数2\n",
    "# rnn_seq = nn.RNN(5, 10, 2)  \n",
    "# 构造一个输入序列，句长为 6，batch 是 3， 每个单词使用长度是 5的向量表示\n",
    "# x = torch.randn(6, 3, 5) # 6是seq_len，3是batch_size, 5是input_dim和上面的5要对应起来\n",
    "# out,ht = rnn_seq(x) #h0可以指定或者不指定，或者 out,ht = rnn_seq(x,h0) 指定h0\n",
    "\n",
    "# 问题1：这里out、ht的size是多少呢？\n",
    "# 回答：out:6 * 3 * 10, ht: 2 * 3 * 10，\n",
    "# out的输出维度[seq_len, batch_size, output_dim]，ht的维度[num_layers * num_directions, batch, hidden_size],\n",
    "# 如果是单向单层的RNN那么一个句子只有一个hidden。num_directions应该是单向的是1，双向的是2\n",
    "# liujia: 这里的output_dim应该和hidden_size一样吧。。。。见问题2，就是一样的\n",
    "# liujia: out的输出维度，最后一维应该是out_dim * n_direction?\n",
    "\n",
    "# 问题2：out[-1]和ht[-1]是否相等？\n",
    "# 回答：相等，隐藏单元就是输出的最后一个单元，可以想象，每个的输出其实就是那个时间步的隐藏单元\n",
    "\n",
    "# RNN的其它参数\n",
    "# RNN(input_dim ,hidden_dim ,num_layers ，…)\n",
    "# – input_dim 表示输入的特征维度\n",
    "# – hidden_dim 表示输出的特征维度，如果没有特殊变化，相当于out\n",
    "# – num_layers 表示网络的层数  liujia:多层相当于stack那种架构\n",
    "# – nonlinearity 表示选用的非线性激活函数，默认是 ‘tanh’\n",
    "# – bias 表示是否使用偏置，默认使用  liujia: 这个是什么？输出的out是hidden state经过变换而来的，这个是变换的偏置么？\n",
    "# – batch_first 表示输入数据的形式，默认是 False，就是这样形式，(seq, batch, feature)，也就是将序列长度放在第一位，batch 放在第二位\n",
    "# – dropout 表示是否在输出层应用 dropout   liujia: dropout怎么做？\n",
    "# – bidirectional 表示是否使用双向的 rnn，默认是 False\n",
    "\n",
    "# LSTM的输出多了一个memory单元\n",
    "# 例如：\n",
    "# 输入维度 50，隐层100维，两层\n",
    "# lstm_seq = nn.LSTM(50, 100, num_layers=2)\n",
    "# 输入序列seq=10，batch=3，输入维度=50\n",
    "# lstm_input = torch.randn(10, 3, 50)\n",
    "# out, (h, c) = lstm_seq(lstm_input) # 使用默认的全0隐藏状态\n",
    "\n",
    "# 问题1：out和(h,c)的size各是多少？\n",
    "# 回答：out：(10 * 3 * 100)，(h,c)：都是(2 * 3 * 100) 和上面的传统RNN一样。。。\n",
    "# 问题2：out[-1,:,:]和h[-1,:,:]相等吗？\n",
    "# 回答： 相等\n",
    "\n",
    "# GRU比较像传统的RNN\n",
    "# gru_seq = nn.GRU(10, 20,2) # x_dim,h_dim,layer_num\n",
    "# gru_input = torch.randn(3, 32, 10) # seq，batch，x_dim\n",
    "# out, h = gru_seq(gru_input)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# 通过torch.nn.GRU模块实现编码器的RNN。本模块接受一批语句(嵌入单词的向量)的输入，它在内部遍历这些句子，\n",
    "# 每次一个标记，计算隐藏状态。我们将这个模块初始化为双向的，\n",
    "# 这意味着我们有两个独立的GRUs:一个按时间顺序遍历序列，另一个按相反顺序遍历序列。 \n",
    "# 我们最终返回这两个GRUs输出的和。由于我们的模型是使用批处理进行训练的，\n",
    "# 所以我们的EncoderRNN模型的forward函数需要一个填充的输入批处理。为了批量处理可变长度的句子，\n",
    "# 我们通过MAX_LENGTH令牌允许一个句子中支持的最大长度，并且批处理中所有小于MAX_LENGTH\n",
    "# 令牌的句子都使用我们专用的PAD_token令牌填充在最后。要使用带有PyTorch RNN模块的批量填充，\n",
    "# 我们必须把转发forward密令在 调用torch.nn.utils.rnn.pack_padded_sequence\n",
    "# 和torch.nn.utils.rnn.pad_packed_sequence数据转换时进行打包。注意，forward 函数还接受一个input_length列表，\n",
    "# 其中包含批处理中每个句子的长度。该输入在填充时通过torch.nn.utils.rnn.pack_padded_sequence使用。\n",
    "\n",
    "# 混合前端笔记: 由于编码器的转发函数forward不包含任何依赖于数据的控制流，\n",
    "# 因此我们将使用跟踪tracing将其转换为脚本模式script mode。\n",
    "# 在跟踪模块时，我们可以保持模块定义不变。在运行评估之前，我们将在本文末尾初始化所有模型。\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "\n",
    "        # 初始化GRU;input_size和hidden_size参数都设置为'hidden_size'\n",
    "        # 因为我们输入的大小是一个有多个特征的词向量== hidden_size\n",
    "        self.gru = nn.GRU(hidden_size,   #input_dim设置为何hidden_size一样\n",
    "                          hidden_size, \n",
    "                          n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout), \n",
    "                          bidirectional=True)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        # 将单词索引转换为向量\n",
    "        embedded = self.embedding(input_seq)\n",
    "        # 为RNN模块填充批次序列   \n",
    "        # liujia: pack_padded_sequence为填充，pad_packed_sequence为对输出再去掉填充\n",
    "        # 不过input_lengths说需要按照从大到小排列，而且第一个参数embedded需要也是这种顺序排列好的，是这样么？\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        # 正向通过GRU\n",
    "        outputs, hidden = self.gru(packed, hidden) #hidden可传可不传，不传就是默认的0\n",
    "        # 打开填充\n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        # 将双向GRU的输出结果总和\n",
    "        # liujia: 如果多层+双向，那么outputs的size是？？？\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
    "        # 返回输出以及最终的隐藏状态\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6.定义解码器的注意力模块\n",
    "\n",
    "# 接下来，将定义注意力模块(Attn)。请注意，此模块将用作解码器模型中的子模块。\n",
    "# Luong等人考虑了各种“分数函数”score functions，它们取当前解码器RNN输出和整个编码器输出，\n",
    "# 并返回关注点“能值”engergies。这个关注能值张量attension energies tensor与编码器输出的大小相同，\n",
    "# 两者最终相乘，得到一个加权张量，其最大值表示在特定时间步长解码的查询语句最重要的部分。\n",
    "\n",
    "# Luong的注意力层\n",
    "class Attn(torch.nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == 'general':\n",
    "            self.attn = torch.nn.Linear(self.hidden_size, hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = torch.nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "\n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "\n",
    "    def general_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(encoder_output)\n",
    "        return torch.sum(hidden * energy, dim=2)\n",
    "\n",
    "    def concat_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # 根据给定的方法计算注意力权重（能量）\n",
    "        if self.method == 'general':\n",
    "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'concat':\n",
    "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'dot':\n",
    "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "\n",
    "        # 转置max_length和batch_size维度\n",
    "        attn_energies = attn_energies.t()\n",
    "\n",
    "        # 返回softmax归一化概率分数（增加维度）\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 7.定义解码器\n",
    "\n",
    "# 类似于EncoderRNN，我们使用torch.nn.GRU模块作为我们的解码器RNN。\n",
    "# 然而，这一次我们使用单向GRU。需要注意的是，与编码器不同，我们将向解码器RNN每次提供一个单词。\n",
    "# 我们首先得到当前单词的嵌入并应用抛出功能dropout。接下来，我们将嵌入和最后的隐藏状态转发给GRU，\n",
    "# 得到当前的GRU输出和隐藏状态。然后，我们使用Attn模块作为一个层来获得专注权重，\n",
    "# 我们将其乘以编码器的输出来获得我们的参与编码器输出。我们使用这个参与编码器输出作为文本context张量，\n",
    "# 它表示一个加权和，表示编码器输出的哪些部分需要注意。 在这里，我们使用线性层linear layer\n",
    "# 和softmax normalization归一化来选择输出序列中的下一个单词。\n",
    "\n",
    "# *混合前端笔记 与EncoderRNN类似，此模块不包含任何依赖于数据的控制流。\n",
    "# 因此，在初始化该模型并加载其参数之后，我们可以再次使用跟踪tracing将其转换为Torch脚本。\n",
    "\n",
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # 保持参考\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # 定义层\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        # 注意：我们这步只运行一次\n",
    "        # 获取当前输入字对应的向量映射\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        # 通过单向GRU转发\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        # 通过当前GRU的输出计算注意力权重\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        # 注意力权重乘以编码器输出以获得新的“加权和”上下文向量\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        # 使用Luong的公式5来连接加权上下文向量和GRU输出\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        # 使用Luong的公式6来预测下一个单词\n",
    "        output = self.out(concat_output)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        # 返回输出和最终的隐藏状态\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "substring not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2ee50cbc0683>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# ```buildoutcfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mGreedySearchDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScriptModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_n_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGreedySearchDecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-2ee50cbc0683>\u001b[0m in \u001b[0;36mGreedySearchDecoder\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscript_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_seq\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;31m# 通过编码器模型转发输入\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mscript_method\u001b[0;34m(fn, _rcb)\u001b[0m\n\u001b[1;32m   1202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_rcb\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m         \u001b[0m_rcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_jit_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateResolutionCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes_up\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m     \u001b[0mast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_jit_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ScriptModule\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mScriptMethodStub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_rcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/torch/jit/frontend.py\u001b[0m in \u001b[0;36mget_jit_def\u001b[0;34m(fn, self_name)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mtype_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSourceContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_lineno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleading_whitespace_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_uses_true_division\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy_ast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/torch/jit/frontend.py\u001b[0m in \u001b[0;36mbuild_def\u001b[0;34m(ctx, py_def, type_line, self_name)\u001b[0m\n\u001b[1;32m    204\u001b[0m     return Def(Ident(r, py_def.name),\n\u001b[1;32m    205\u001b[0m                \u001b[0mdecl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                build_stmts(ctx, body))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/torch/jit/frontend.py\u001b[0m in \u001b[0;36mbuild_stmts\u001b[0;34m(ctx, stmts)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_stmts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstmts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mstmts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbuild_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstmts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstmts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/torch/jit/frontend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_stmts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstmts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mstmts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbuild_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstmts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstmts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/torch/jit/frontend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, ctx, node)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUnsupportedNodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/torch/jit/frontend.py\u001b[0m in \u001b[0;36mbuild_For\u001b[0;34m(ctx, stmt)\u001b[0m\n\u001b[1;32m    339\u001b[0m         return For(\n\u001b[1;32m    340\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbuild_expr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             [build_expr(ctx, stmt.iter)], build_stmts(ctx, stmt.body))\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/torch/jit/frontend.py\u001b[0m in \u001b[0;36mbuild_stmts\u001b[0;34m(ctx, stmts)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_stmts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstmts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mstmts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbuild_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstmts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstmts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/torch/jit/frontend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_stmts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstmts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mstmts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbuild_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstmts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstmts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/torch/jit/frontend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, ctx, node)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUnsupportedNodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/torch/jit/frontend.py\u001b[0m in \u001b[0;36mbuild_Assign\u001b[0;34m(ctx, stmt)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_Assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mrhs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_expr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0mstart_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_offset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/torch/jit/frontend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, ctx, node)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUnsupportedNodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/torch/jit/frontend.py\u001b[0m in \u001b[0;36mbuild_Call\u001b[0;34m(ctx, expr)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_Call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_expr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbuild_expr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy_arg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpy_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'starargs'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/torch/jit/frontend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, ctx, node)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUnsupportedNodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/torch/jit/frontend.py\u001b[0m in \u001b[0;36mbuild_Attribute\u001b[0;34m(ctx, expr)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;31m# <sigh> name is just a string, so it's not annotated in any way.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_after\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m  \u001b[0;31m# Start with the dot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhitespace\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Skip whitespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0mpos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/torch/jit/frontend.py\u001b[0m in \u001b[0;36mfind_after\u001b[0;34m(ctx, pos, substr, offsets)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_after\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0mnew_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_raw_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_pos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_pos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: substring not found"
     ]
    }
   ],
   "source": [
    "# 8.定义评估\n",
    "\n",
    "# 8.1 贪婪搜索解码器\n",
    "# 在聊天机器人教程中，我们使用GreedySearchDecoder模块来简化实际的解码过程。\n",
    "# 该模块将训练好的编码器和解码器模型作为属性，驱动输入语句(词索引向量)的编码过程，并一次一个词(词索引)迭代地解码输出响应序列。\n",
    "\n",
    "# 对输入序列进行编码很简单:只需将整个序列张量及其对应的长度向量转发给编码器。需要注意的是，\n",
    "# 这个模块一次只处理一个输入序列，而不是成批的序列。因此，当常数1用于声明张量大小时，\n",
    "# 它对应于批处理大小为1。要解码给定的解码器输出，我们必须通过解码器模型 迭代地向前运行，\n",
    "#该解码器模型输出softmax分数，该分数对应于每个单词在解码序列中是正确的下一个单词的概率。\n",
    "# 我们将decoder_input初始化为一个包含SOS_token的张量。在每次通过解码器之后，\n",
    "# 我们贪婪地将softmax概率最高的单词追加到decoded_words列表中。 \n",
    "# 我们还使用这个单词作为下一个迭代的decoder_input。如果decoded_words列表的长度达到MAX_LENGTH，\n",
    "# 或者预测的单词是EOS_token，那么解码过程将终止。\n",
    "\n",
    "# ```buildoutcfg\n",
    "class GreedySearchDecoder(torch.jit.ScriptModule): \n",
    "    def init(self, encoder, decoder, decoder_n_layers): \n",
    "        super(GreedySearchDecoder, self).init() \n",
    "        self.encoder = encoder \n",
    "        self.decoder = decoder \n",
    "        self._device = device \n",
    "        self._SOS_token = SOS_token \n",
    "        self._decoder_n_layers = decoder_n_layers\n",
    "\n",
    "    constants = ['_device', '_SOS_token', '_decoder_n_layers']\n",
    "\n",
    "    @torch.jit.script_method \n",
    "    def forward(self, input_seq : torch.Tensor, input_length : torch.Tensor, max_length : int): \n",
    "        # 通过编码器模型转发输入 \n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length) \n",
    "        # 准备编码器的最终隐藏层作为解码器的第一个隐藏输入 \n",
    "        decoder_hidden = encoder_hidden[:self._decoder_n_layers] \n",
    "        # 使用SOS_token初始化解码器输入 \n",
    "        decoder_input = torch.ones(1, 1, device=self._device, dtype=torch.long) * self._SOS_token \n",
    "        # 初始化张量以将解码后的单词附加到 \n",
    "        all_tokens = torch.zeros([0], device=self._device, dtype=torch.long) \n",
    "        all_scores = torch.zeros([0], device=self._device) \n",
    "        # 一次迭代地解码一个词令牌 \n",
    "        for _ in range(max_length): \n",
    "            # 正向通过解码器 \n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs) \n",
    "            # 获得最可能的单词标记及其softmax分数 \n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1) \n",
    "            # 记录令牌和分数 \n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0) \n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0) \n",
    "            # 准备当前令牌作为下一个解码器输入（添加维度） \n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0) \n",
    "            \n",
    "        # 返回词令牌和分数的集合 \n",
    "        return all_tokens, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 8.2 输入评估\n",
    "\n",
    "# 接下来，我们定义一些函数来计算输入。求值函数`evaluate`接受一个规范化字符串语句，将其处理为其对应的单词索引张量(批处理大小\n",
    "# 为1)，并将该张量传递给一个名为`searcher`的`GreedySearchDecoder`实例，以处理编码/解码过程。检索器返回输出的单词索引向量和\n",
    "# 一个分数张量，该张量对应于每个解码的单词标记的`softmax`分数。最后一步是使用`voc.index2word`将每个单词索引转换回其字符串表示形式。\n",
    "\n",
    "# 我们还定义了两个函数来计算输入语句。`evaluateInput`函数提示用户输入，并计算输入。它持续请求另一次输入，直到用户输入“q”或“quit”。\n",
    "\n",
    "# `evaluateExample`函数只接受一个字符串输入语句作为参数，对其进行规范化、计算并输出响应。\n",
    "# ```buildoutcfg\n",
    "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n",
    "    # 格式化输入句子作为批处理\n",
    "    # words -> indexes\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
    "    # 创建长度张量\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # 转置批量的维度以匹配模型的期望\n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    # 使用适当的设备\n",
    "    input_batch = input_batch.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    # 用earcher解码句子s\n",
    "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
    "    # indexes -> words\n",
    "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words\n",
    "\n",
    "\n",
    "# 评估来自用户输入的输入(stdin)\n",
    "def evaluateInput(encoder, decoder, searcher, voc):\n",
    "    input_sentence = ''\n",
    "    while(1):\n",
    "        try:\n",
    "            # 获取输入的句子\n",
    "            input_sentence = input('> ')\n",
    "            # Check if it is quit case\n",
    "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            # 规范化句子\n",
    "            input_sentence = normalizeString(input_sentence)\n",
    "            # 评估句子\n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "            # 格式化和打印回复句\n",
    "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "            print('Bot:', ' '.join(output_words))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")\n",
    "\n",
    "# 规范化输入句子并调用evaluate()\n",
    "def evaluateExample(sentence, encoder, decoder, searcher, voc):\n",
    "    print(\"> \" + sentence)\n",
    "    # 规范化句子\n",
    "    input_sentence = normalizeString(sentence)\n",
    "    # 评估句子\n",
    "    output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "    output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "    print('Bot:', ' '.join(output_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building encoder and decoder ...\n",
      "Models built and ready to go!\n"
     ]
    }
   ],
   "source": [
    "# 9.加载预训练参数\n",
    "\n",
    "# 9.1 使用托管模型\n",
    "# 托管模型使用步骤:\n",
    "# 1.下载模型这里: https://download.pytorch.org/models/tutorials/4000_checkpoint.tar\n",
    "# 2.设置loadFilename变量作为下载的检查点文件的路径 \n",
    "# 3.将checkpoint = torch.load(loadFilename)行取消注释，表示托管模型在CPU上训练。\n",
    "\n",
    "# 9.2 使用自己的模型\n",
    "# 加载自己的预训练模型设计步骤:\n",
    "# 1.将loadFilename变量设置为希望加载的检查点文件的路径。注意，如果您遵循从chatbot tutorial中保存模型的协议，\n",
    "# 这会涉及更改 model_name、encoder_n_layers、decoder_n_layers、hidden_size和checkpoint_iter(因为这些值在模型路径中使用到)。 \n",
    "# 2.如果你在CPU上训练，确保你在checkpoint = torch.load(loadFilename)行打开了检查点。\n",
    "# 如果你在GPU上训练，并且在CPU运行这篇 教程，解除checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))的注释。\n",
    "\n",
    "# 请注意，我们像往常一样初始化并将参数加载到编码器和解码器模型中。\n",
    "# 另外，在跟踪模型之前，我们必须调用.to(device)来设置模型的设备选项，\n",
    "# 调用.eval()来设置抛出层dropout layer为test mode。\n",
    "# TracedModule对象不继承to或eval方法。\n",
    "\n",
    "save_dir = os.path.join(\"data\", \"save\")\n",
    "corpus_name = \"cornell movie-dialogs corpus\"\n",
    "\n",
    "# 配置模型\n",
    "model_name = 'cb_model'\n",
    "attn_model = 'dot'\n",
    "#attn_model = 'general'\n",
    "#attn_model = 'concat'\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 64\n",
    "\n",
    "# 如果你加载的是自己的模型\n",
    "# 设置要加载的检查点\n",
    "checkpoint_iter = 4000\n",
    "# loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
    "#                             '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
    "#                             '{}_checkpoint.tar'.format(checkpoint_iter))\n",
    "\n",
    "# 如果你加载的是托管模型\n",
    "loadFilename = 'data/4000_checkpoint.tar'\n",
    "\n",
    "# 加载模型\n",
    "# 强制CPU设备选项（与本教程中的张量匹配）\n",
    "checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
    "encoder_sd = checkpoint['en']\n",
    "decoder_sd = checkpoint['de']\n",
    "encoder_optimizer_sd = checkpoint['en_opt']\n",
    "decoder_optimizer_sd = checkpoint['de_opt']\n",
    "embedding_sd = checkpoint['embedding']\n",
    "\n",
    "# liujia: 相当于直接初始化voc对象的各个值了，即直接赋值voc对象的__dict__\n",
    "# python类的静态函数、类函数、普通函数、全局变量以及一些内置的属性都是放在类__dict__里的\n",
    "# 对象的__dict__中存储了一些self.xxx的一些东西\n",
    "# python里除了int等一些内置对象外，都有__dict__\n",
    "voc = Voc(corpus_name)\n",
    "voc.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "#print(len(voc.__dict__))\n",
    "#print(voc.__dict__)\n",
    "\n",
    "\n",
    "print('Building encoder and decoder ...')\n",
    "# 初始化词向量  liujia:\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "embedding.load_state_dict(embedding_sd)\n",
    "# 初始化编码器和解码器模型\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "# 加载训练模型参数\n",
    "encoder.load_state_dict(encoder_sd)\n",
    "decoder.load_state_dict(decoder_sd)\n",
    "# 使用适当的设备\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "# 将dropout层设置为eval模式\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "print('Models built and ready to go!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GreedySearchDecoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-55aec63adc2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m### 初始化searcher模块\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mscripted_searcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGreedySearchDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraced_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraced_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'GreedySearchDecoder' is not defined"
     ]
    }
   ],
   "source": [
    "# 10.将模型转换为 Torch 脚本\n",
    "\n",
    "# 10.1 编码器\n",
    "# 正如前文所述，要将编码器模型转换为Torch脚本，我们需要使用跟踪Tracing。\n",
    "# 跟踪任何需要通过模型的forward方法运行一个示例输入，以及跟踪数据相遇时的图形计算。\n",
    "# 编码器模型接收一个输入序列和一个长度相关的张量。因此，我们创建一个输入序列test_seq，\n",
    "# 配置合适的大小(MAX_LENGTH,1)包含适当范围内的数值([0,voc.num_words])以及搭配的类型(int64)。\n",
    "# 我们还创建了test_seq_length 标量，该标量实际包含与test_seq中单词数量对应的值。\n",
    "# 下一步是使用torch.jit.trace函数来跟踪模型。\n",
    "# 注意，我们传递的第一个参数是要跟踪的模块，第二个参数是模块forward方法的参数元组。\n",
    "\n",
    "# 10.2 解码器\n",
    "# 我们对解码器的跟踪过程与对编码器的跟踪过程相同。\n",
    "# 请注意，我们对traced_encoder的一组随机输入调用forward，以获得解码器所需的输出。\n",
    "# 这不是必需的，因为我们也可以简单地生成一个形状、类型和值范围正确的张量。\n",
    "# 这种方法是可行的，因为在我们的例子中，我们对张量的值没有任何约束，因为我们没有任何操作可能导致超出范围的输入出错。\n",
    "\n",
    "# 10.3 贪婪搜索解码器\n",
    "# 回想一下，由于存在依赖于数据的控制流，我们为搜索器模块编写了脚本。\n",
    "# 在脚本化的情况下，我们通过添加修饰符并确保实现符合脚本规则来预先完成转换工作。\n",
    "# 我们初始化脚本搜索器的方式与初始化未脚本化变量的方式相同。\n",
    "\n",
    "### 转换编码器模型\n",
    "# 创建人工输入\n",
    "test_seq = torch.LongTensor(MAX_LENGTH, 1).random_(0, voc.num_words).to(device)\n",
    "test_seq_length = torch.LongTensor([test_seq.size()[0]]).to(device)\n",
    "# 跟踪模型\n",
    "traced_encoder = torch.jit.trace(encoder, (test_seq, test_seq_length))\n",
    "\n",
    "### 转换解码器模型\n",
    "# 创建并生成人工输入\n",
    "test_encoder_outputs, test_encoder_hidden = traced_encoder(test_seq, test_seq_length)\n",
    "test_decoder_hidden = test_encoder_hidden[:decoder.n_layers]\n",
    "test_decoder_input = torch.LongTensor(1, 1).random_(0, voc.num_words)\n",
    "# 跟踪模型\n",
    "traced_decoder = torch.jit.trace(decoder, (test_decoder_input, test_decoder_hidden, test_encoder_outputs))\n",
    "\n",
    "### 初始化searcher模块\n",
    "scripted_searcher = GreedySearchDecoder(traced_encoder, traced_decoder, decoder.n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
